import streamlit as st
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys
import random
import logging
import warnings

# å½»åº•è¿‡æ»¤æ‰æ‰€æœ‰è­¦å‘Šï¼ŒåŒ…æ‹¬matplotlibå­—ä½“è­¦å‘Šå’ŒPyTorchè­¦å‘Š
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', module='matplotlib')
warnings.filterwarnings('ignore', module='matplotlib.font_manager')
warnings.filterwarnings('ignore', module='torch')
warnings.filterwarnings('ignore', module='torch._classes')

import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯é¿å…å­—ä½“é—®é¢˜

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ·»åŠ ç»„ä»¶è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'components'))

from model_loader import ModelLoader
from csi_processor import CSIProcessor
from visualizer import (
    plot_csi_heatmap, 
    plot_model_comparison_bar,
    plot_performance_radar
)
from results_loader import ResultsLoader

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŸºäºæ·±åº¦å­¦ä¹ çš„WiFi CSIå¤šç»´æƒ…æ™¯æ„ŸçŸ¥å¹³å°",
    page_icon="ğŸ“¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–
@st.cache_resource
def init_loaders():
    """åˆå§‹åŒ–åŠ è½½å™¨"""
    model_loader = ModelLoader()
    csi_processor = CSIProcessor()
    results_loader = ResultsLoader()
    return model_loader, csi_processor, results_loader

model_loader, csi_processor, results_loader = init_loaders()

def create_dummy_csi_data():
    """åˆ›å»ºè™šæ‹ŸCSIæ•°æ®ç”¨äºæ¼”ç¤º"""
    # åˆ›å»º500ä¸ªæ—¶é—´æ­¥ï¼Œ56ä¸ªç‰¹å¾çš„è™šæ‹Ÿæ•°æ®
    time_steps = 500
    features = 56
    
    # åˆ›å»ºä¸€äº›æœ‰æ¨¡å¼çš„æ•°æ®
    t = np.linspace(0, 4*np.pi, time_steps)
    data = np.zeros((time_steps, features))
    
    for i in range(features):
        # ä¸åŒé¢‘ç‡çš„æ­£å¼¦æ³¢æ¨¡æ‹Ÿä¸åŒå­è½½æ³¢
        frequency = 0.1 + (i / features) * 2
        amplitude = 0.5 + 0.5 * np.sin(i * 0.1)
        noise = np.random.normal(0, 0.1, time_steps)
        data[:, i] = amplitude * np.sin(frequency * t) + noise
    
    return data

def main():
    """ä¸»å‡½æ•°"""
    # ä¾§è¾¹æ é€‰æ‹©æ¨¡å¼
    st.sidebar.title("é€‰æ‹©æ¨¡å¼")
    mode = st.sidebar.radio(
        "è¯·é€‰æ‹©ä½¿ç”¨æ¨¡å¼ï¼š",
        ["ğŸ”¬ ç ”ç©¶æ¨¡å¼", "ğŸ® æ¸¸æˆæ¨¡å¼"],
        help="ç ”ç©¶æ¨¡å¼ï¼šæŸ¥çœ‹æˆ‘çš„å®éªŒç»“æœå’Œæ•°æ®åˆ†æï¼›æ¸¸æˆæ¨¡å¼ï¼šå’ŒAIæ¯”èµ›çŒœCSIæ´»åŠ¨ï¼Œå¾ˆå¥½ç©ï¼"
    )
    
    if mode == "ğŸ”¬ ç ”ç©¶æ¨¡å¼":
        # åªåœ¨ç ”ç©¶æ¨¡å¼æ˜¾ç¤ºä»‹ç»å†…å®¹
        st.title("ğŸ“¡ åŸºäºæ·±åº¦å­¦ä¹ çš„WiFi CSIå¤šç»´æƒ…æ™¯æ„ŸçŸ¥")
        st.markdown("""
        ğŸ‘¨â€ğŸ“ **è¯¾é¢˜å†…å®¹**ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„çœŸå®å¤æ‚ç¯å¢ƒWiFi CSIå¤šç»´æƒ…æ™¯æ„ŸçŸ¥ç ”ç©¶
        
        è¿™æ˜¯æˆ‘çš„æœŸæœ«å¤§ä½œä¸šæˆæœå±•ç¤ºï¼æœ¬ä½œä¸šç ”ç©¶äº†å¦‚ä½•ä½¿ç”¨WiFi CSI(Channel State Information)æ•°æ®è¿›è¡Œäººä½“æ´»åŠ¨è¯†åˆ«ã€‚
        æˆ‘æµ‹è¯•äº†7ç§æ·±åº¦å­¦ä¹ æ¨¡å‹(MLPã€LSTMã€ResNet18ã€Transformerã€ViTã€PatchTSTã€TimesFormer1D)ï¼Œ
        å¹¶åœ¨è·¨è®¾å¤‡ã€è·¨ç¯å¢ƒã€è·¨ç”¨æˆ·ç­‰åœºæ™¯ä¸‹è¿›è¡Œäº†æ€§èƒ½è¯„ä¼°ã€‚è¿˜åšäº†ä¸ªå°æ¸¸æˆç”¨äºä½“éªŒCSIæ„ŸçŸ¥æŠ€æœ¯ï¼ğŸ®
        """)
        research_mode()
    else:
        # æ¸¸æˆæ¨¡å¼ç®€æ´æ˜¾ç¤º
        game_mode()

def research_mode():
    """ç ”ç©¶æ¨¡å¼ç•Œé¢"""
    st.header("ğŸ”¬ ç ”ç©¶æ¨¡å¼ - æˆ‘çš„å®éªŒç»“æœ")
    
    # æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”", 
        "ğŸ§  å•ä»»åŠ¡åˆ†æ", 
        "ğŸ¯ å¤šä»»åŠ¡åˆ†æ", 
        "ğŸ”„ è·¨åŸŸæ³›åŒ–"
    ])
    
    with tab1:
        show_model_comparison()
    
    with tab2:
        show_single_task_analysis()
    
    with tab3:
        show_multi_task_analysis()
    
    with tab4:
        show_cross_domain_analysis()

def show_model_comparison():
    """æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯”"""
    st.subheader("ğŸ“Š æ¨¡å‹æ€§èƒ½å…¨é¢å¯¹æ¯”")
    
    # è·å–æ¨¡å‹å¯¹æ¯”æ•°æ®
    comparison_data = results_loader.get_model_comparison_data()
    
    if not comparison_data:
        st.warning("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹å¯¹æ¯”æ•°æ®ï¼Œè¯·æ£€æŸ¥resultsç›®å½•")
        return
    
    # åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾
    col1, col2 = st.columns(2)
    
    with col1:
        # æ¡å½¢å›¾å¯¹æ¯”
        fig = plot_model_comparison_bar(comparison_data, "æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        if fig:
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # æ€§èƒ½æ’åè¡¨
        st.subheader("ğŸ“ˆ æ€§èƒ½æ’å")
        
        # è½¬æ¢æ•°æ®ä¸ºDataFrame
        df_data = []
        for model, metrics in comparison_data.items():
            df_data.append({
                'æ¨¡å‹': model.upper(),
                'æµ‹è¯•å‡†ç¡®ç‡': f"{metrics['test_accuracy']:.3f}",
                'è·¨è®¾å¤‡': f"{metrics['cross_device']:.3f}",
                'è·¨ç¯å¢ƒ': f"{metrics['cross_env']:.3f}",
                'è·¨ç”¨æˆ·': f"{metrics['cross_user']:.3f}",
                'F1åˆ†æ•°': f"{metrics['test_f1']:.3f}"
            })
        
        df = pd.DataFrame(df_data)
        st.dataframe(df, use_container_width=True)
    
    # æœ€ä½³æ¨¡å‹ä¿¡æ¯
    st.subheader("ğŸ† æœ€ä½³æ¨¡å‹")
    best_models = results_loader.get_best_model_info()
    
    if best_models:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "ğŸ¯ æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡",
                f"{best_models['test_accuracy']['model'].upper()}",
                f"{best_models['test_accuracy']['accuracy']:.3f}"
            )
        
        with col2:
            st.metric(
                "ğŸ“± æœ€ä½³è·¨è®¾å¤‡",
                f"{best_models['cross_device']['model'].upper()}",
                f"{best_models['cross_device']['accuracy']:.3f}"
            )
        
        with col3:
            st.metric(
                "ğŸŒ æœ€ä½³è·¨ç¯å¢ƒ",
                f"{best_models['cross_env']['model'].upper()}",
                f"{best_models['cross_env']['accuracy']:.3f}"
            )
        
        with col4:
            st.metric(
                "ğŸ‘¤ æœ€ä½³è·¨ç”¨æˆ·",
                f"{best_models['cross_user']['model'].upper()}",
                f"{best_models['cross_user']['accuracy']:.3f}"
            )

def plot_training_history_comparison(train_histories, metric='accuracy', selected_datasets=None):
    """
    åˆ›å»ºæ‰€æœ‰æ¨¡å‹è®­ç»ƒå†å²çš„å¯¹æ¯”å›¾
    
    Args:
        train_histories: dict, åŒ…å«æ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒå†å²æ•°æ®
        metric: str, 'accuracy' æˆ– 'loss'
        selected_datasets: list, è¦æ˜¾ç¤ºçš„æ•°æ®é›†åˆ—è¡¨ ['train', 'val']
    
    Returns:
        plotly figure
    """
    try:
        fig = go.Figure()
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹æ·»åŠ ä¸€æ¡çº¿
        for model_name, history in train_histories.items():
            if metric == 'accuracy':
                train_col = 'Train Accuracy'
                val_col = 'Val Accuracy'
                title = "æ¨¡å‹è®­ç»ƒå‡†ç¡®ç‡å¯¹æ¯”"
                yaxis_title = "å‡†ç¡®ç‡"
            else:
                train_col = 'Train Loss'
                val_col = 'Val Loss'
                title = "æ¨¡å‹è®­ç»ƒæŸå¤±å¯¹æ¯”"
                yaxis_title = "æŸå¤±"
            
            # æ ¹æ®é€‰æ‹©çš„æ•°æ®é›†æ·»åŠ æ›²çº¿
            if 'train' in selected_datasets:
                fig.add_trace(go.Scatter(
                    x=history['Epoch'],
                    y=history[train_col],
                    name=f"{model_name} (è®­ç»ƒé›†)",
                    line=dict(dash='solid'),
                    legendgroup=model_name
                ))
            
            if 'val' in selected_datasets:
                fig.add_trace(go.Scatter(
                    x=history['Epoch'],
                    y=history[val_col],
                    name=f"{model_name} (éªŒè¯é›†)",
                    line=dict(dash='dot'),
                    legendgroup=model_name
                ))
        
        fig.update_layout(
            title=title,
            xaxis_title="Epoch",
            yaxis_title=yaxis_title,
            hovermode='x unified',
            legend=dict(
                groupclick="toggleitem",
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        
        return fig
    except Exception as e:
        st.warning(f"åˆ›å»ºè®­ç»ƒå†å²å¯¹æ¯”å›¾æ—¶å‡ºé”™: {e}")
        return None

def show_single_task_analysis():
    """æ˜¾ç¤ºå•ä»»åŠ¡åˆ†æ"""
    st.subheader("ğŸ¯ å•ä»»åŠ¡å­¦ä¹ åˆ†æ")
    
    # è·å–å•ä»»åŠ¡æ•°æ®
    single_task_data = results_loader.load_single_task_results()
    
    if not single_task_data:
        st.warning("âŒ æ²¡æœ‰æ‰¾åˆ°å•ä»»åŠ¡æ•°æ®")
        return
    
    # æ¨¡å‹é€‰æ‹©ï¼ˆç”¨äºè¯¦ç»†åˆ†æï¼‰
    model_names = list(single_task_data.keys())
    selected_model = st.selectbox("é€‰æ‹©è¦è¯¦ç»†åˆ†æçš„æ¨¡å‹:", model_names)
    model_data = single_task_data[selected_model]
    
    # è®­ç»ƒå†å²
    st.subheader("ğŸ“ˆ è®­ç»ƒå†å²")
    
    # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„è®­ç»ƒå†å²
    train_histories = {}
    for model_name, data in single_task_data.items():
        if 'train_history' in data:
            train_histories[model_name] = data['train_history']
    
    if train_histories:
        # åˆ›å»ºä¸¤åˆ—ç”¨äºé€‰æ‹©
        col1, col2 = st.columns(2)
        
        with col1:
            # æ¨¡å‹å¤šé€‰
            available_models = list(train_histories.keys())
            default_models = [selected_model] if selected_model in available_models else [available_models[0]]
            selected_models = st.multiselect(
                "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹:",
                options=available_models,
                default=default_models,
                help="å¯ä»¥é€‰æ‹©å¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”"
            )
        
        with col2:
            # æ•°æ®é›†é€‰æ‹©
            dataset_options = {
                'train': 'è®­ç»ƒé›†',
                'val': 'éªŒè¯é›†'
            }
            selected_datasets = st.multiselect(
                "é€‰æ‹©è¦æ˜¾ç¤ºçš„æ•°æ®é›†:",
                options=list(dataset_options.keys()),
                default=['train', 'val'],
                format_func=lambda x: dataset_options[x],
                help="å¯ä»¥é€‰æ‹©æ˜¾ç¤ºè®­ç»ƒé›†å’Œ/æˆ–éªŒè¯é›†çš„æ•°æ®"
            )
        
        if not selected_models:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
            return
        
        if not selected_datasets:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ•°æ®é›†")
            return
        
        # åˆ›å»ºæ ‡ç­¾é¡µæ¥åˆ†åˆ«æ˜¾ç¤ºå‡†ç¡®ç‡å’ŒæŸå¤±
        tab1, tab2 = st.tabs(["å‡†ç¡®ç‡å¯¹æ¯”", "æŸå¤±å¯¹æ¯”"])
        
        # è¿‡æ»¤é€‰ä¸­çš„æ¨¡å‹æ•°æ®
        filtered_histories = {
            model: history for model, history in train_histories.items() 
            if model in selected_models
        }
        
        with tab1:
            fig_acc = plot_training_history_comparison(
                filtered_histories, 
                metric='accuracy',
                selected_datasets=selected_datasets
            )
            if fig_acc:
                st.plotly_chart(fig_acc, use_container_width=True)
        
        with tab2:
            fig_loss = plot_training_history_comparison(
                filtered_histories, 
                metric='loss',
                selected_datasets=selected_datasets
            )
            if fig_loss:
                st.plotly_chart(fig_loss, use_container_width=True)
    else:
        st.info("æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå†å²æ•°æ®")
    
    # æ··æ·†çŸ©é˜µ
    st.subheader("ğŸ¯ æ··æ·†çŸ©é˜µ")
    if 'confusion_matrices' in model_data:
        split_options = list(model_data['confusion_matrices'].keys())
        selected_split = st.selectbox("é€‰æ‹©æ•°æ®é›†:", split_options)
        
        img = results_loader.load_confusion_matrix_image(
            selected_model, selected_split, 'single_task'
        )
        if img:
            st.image(img, caption=f"{selected_model.upper()} - {selected_split} æ··æ·†çŸ©é˜µ")
        else:
            st.warning(f"æ— æ³•åŠ è½½ {selected_split} çš„æ··æ·†çŸ©é˜µå›¾ç‰‡")
    
    # åˆ†ç±»æŠ¥å‘Š
    if 'classification_reports' in model_data:
        st.subheader("ğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š")
        split_options = list(model_data['classification_reports'].keys())
        selected_split = st.selectbox("é€‰æ‹©æ•°æ®é›†:", split_options, key="report_split")
        
        if selected_split in model_data['classification_reports']:
            report_df = model_data['classification_reports'][selected_split]
            st.dataframe(report_df, use_container_width=True)

def show_multi_task_analysis():
    """æ˜¾ç¤ºå¤šä»»åŠ¡åˆ†æ"""
    st.subheader("ğŸ¯ å¤šä»»åŠ¡å­¦ä¹ åˆ†æ")
    
    # è·å–å¤šä»»åŠ¡æ•°æ®
    multi_task_data = results_loader.get_multi_task_comparison_data()
    
    if not multi_task_data:
        st.warning("âŒ æ²¡æœ‰æ‰¾åˆ°å¤šä»»åŠ¡æ•°æ®")
        return
    
    # ä»»åŠ¡é€‰æ‹©
    task_names = list(multi_task_data.keys())
    selected_task = st.selectbox("é€‰æ‹©ä»»åŠ¡:", task_names)
    
    task_data = multi_task_data[selected_task]
    
    # ä»»åŠ¡æ€§èƒ½å¯¹æ¯”
    col1, col2 = st.columns(2)
    
    with col1:
        # åˆ›å»ºå¯¹æ¯”å›¾
        fig = plot_model_comparison_bar(task_data, f"{selected_task} æ¨¡å‹å¯¹æ¯”")
        if fig:
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # æ€§èƒ½è¡¨æ ¼
        st.subheader("ğŸ“Š æ€§èƒ½è¯¦æƒ…")
        df_data = []
        for model, metrics in task_data.items():
            df_data.append({
                'æ¨¡å‹': model.upper(),
                'æµ‹è¯•å‡†ç¡®ç‡': f"{metrics['test_accuracy']:.3f}",
                'è·¨è®¾å¤‡': f"{metrics['cross_device']:.3f}",
                'è·¨ç¯å¢ƒ': f"{metrics['cross_env']:.3f}",
                'è·¨ç”¨æˆ·': f"{metrics['cross_user']:.3f}"
            })
        
        df = pd.DataFrame(df_data)
        st.dataframe(df, use_container_width=True)
    
    # ä»»åŠ¡é—´å¯¹æ¯”
    st.subheader("ğŸ“ˆ ä»»åŠ¡é—´æ€§èƒ½å¯¹æ¯”")
    
    # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡çš„å¯¹æ¯”å›¾
    all_task_data = {}
    for task, models in multi_task_data.items():
        for model, metrics in models.items():
            if model not in all_task_data:
                all_task_data[model] = {}
            all_task_data[model][task] = metrics['test_accuracy']
    
    if all_task_data:
        try:
            # è½¬æ¢ä¸ºDataFrameç”¨äºå¯è§†åŒ–
            comparison_df = pd.DataFrame(all_task_data).T
            comparison_df = comparison_df.fillna(0)
            
            # é‡å¡‘æ•°æ®ç”¨äºplotly
            melted_df = comparison_df.reset_index().melt(id_vars='index', var_name='ä»»åŠ¡', value_name='å‡†ç¡®ç‡')
            melted_df.rename(columns={'index': 'æ¨¡å‹'}, inplace=True)
            
            fig = px.bar(melted_df, x='æ¨¡å‹', y='å‡†ç¡®ç‡', color='ä»»åŠ¡',
                        title="æ‰€æœ‰ä»»åŠ¡çš„æ¨¡å‹æ€§èƒ½å¯¹æ¯”",
                        labels={'å‡†ç¡®ç‡': 'å‡†ç¡®ç‡', 'æ¨¡å‹': 'æ¨¡å‹'})
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.warning(f"æ— æ³•æ˜¾ç¤ºä»»åŠ¡å¯¹æ¯”å›¾è¡¨: {e}")
            # æ˜¾ç¤ºç®€å•çš„è¡¨æ ¼ä½œä¸ºå¤‡ç”¨
            comparison_df = pd.DataFrame(all_task_data).T
            comparison_df = comparison_df.fillna(0)
            st.dataframe(comparison_df, use_container_width=True)

def plot_cross_domain_comparison(model_results, selected_models, selected_datasets):
    """
    åˆ›å»ºè·¨åŸŸæ³›åŒ–èƒ½åŠ›çš„æŠ˜çº¿å›¾å¯¹æ¯”
    
    Args:
        model_results: dict, åŒ…å«æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½æ•°æ®
        selected_models: list, é€‰ä¸­çš„æ¨¡å‹åˆ—è¡¨
        selected_datasets: list, é€‰ä¸­çš„æ•°æ®é›†åˆ—è¡¨
    
    Returns:
        plotly figure
    """
    try:
        fig = go.Figure()
        
        # æ•°æ®é›†æ˜ å°„
        dataset_mapping = {
            'test': 'In-Domain Test',
            'test_cross_device': 'Cross-Device',
            'test_cross_env': 'Cross-Environment',
            'test_cross_user': 'Cross-User'
        }
        
        # æ•°æ®é›†åˆ°æŒ‡æ ‡çš„æ˜ å°„
        dataset_to_metric = {
            'test': 'test_accuracy',
            'test_cross_device': 'cross_device',
            'test_cross_env': 'cross_env',
            'test_cross_user': 'cross_user'
        }
        
        # ä¸ºæ¯ä¸ªé€‰ä¸­çš„æ¨¡å‹æ·»åŠ ä¸€æ¡çº¿
        for model in selected_models:
            if model in model_results:
                # æ”¶é›†è¯¥æ¨¡å‹åœ¨æ‰€æœ‰é€‰ä¸­æ•°æ®é›†ä¸Šçš„æ€§èƒ½
                accuracies = []
                for dataset in selected_datasets:
                    metric = dataset_to_metric[dataset]
                    acc = model_results[model].get(metric, 0)
                    accuracies.append(acc)
                
                # æ·»åŠ æŠ˜çº¿
                fig.add_trace(go.Scatter(
                    x=[dataset_mapping[d] for d in selected_datasets],
                    y=accuracies,
                    name=model.upper(),
                    mode='lines+markers',
                    marker=dict(size=8)
                ))
        
        fig.update_layout(
            title="æ¨¡å‹è·¨åŸŸæ³›åŒ–èƒ½åŠ›å¯¹æ¯”",
            xaxis_title="æ•°æ®é›†",
            yaxis_title="å‡†ç¡®ç‡",
            hovermode='x unified',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            yaxis=dict(
                range=[0, 1],  # å‡†ç¡®ç‡èŒƒå›´ä»0åˆ°1
                tickformat='.2%'  # æ˜¾ç¤ºä¸ºç™¾åˆ†æ¯”
            )
        )
        
        return fig
    except Exception as e:
        st.warning(f"åˆ›å»ºè·¨åŸŸæ³›åŒ–å¯¹æ¯”å›¾æ—¶å‡ºé”™: {e}")
        return None

def plot_cross_domain_radar(model_results, selected_models):
    """
    åˆ›å»ºè·¨åŸŸæ³›åŒ–èƒ½åŠ›çš„é›·è¾¾å›¾
    
    Args:
        model_results: dict, åŒ…å«æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½æ•°æ®
        selected_models: list, é€‰ä¸­çš„æ¨¡å‹åˆ—è¡¨
    
    Returns:
        plotly figure
    """
    try:
        fig = go.Figure()
        
        # æ•°æ®é›†æ˜ å°„
        dataset_mapping = {
            'test_accuracy': 'In-Domain Test',
            'cross_device': 'Cross-Device',
            'cross_env': 'Cross-Environment',
            'cross_user': 'Cross-User'
        }
        
        metrics = list(dataset_mapping.keys())
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2']
        
        for i, model in enumerate(selected_models):
            if model in model_results:
                # æ”¶é›†è¯¥æ¨¡å‹åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šçš„æ€§èƒ½
                values = []
                for metric in metrics:
                    values.append(model_results[model].get(metric, 0))
            values.append(values[0])  # é—­åˆé›·è¾¾å›¾
            
                # æ·»åŠ é›·è¾¾å›¾è½¨è¿¹
            fig.add_trace(go.Scatterpolar(
                r=values,
                    theta=list(dataset_mapping.values()) + [list(dataset_mapping.values())[0]],
                fill='toself',
                name=model.upper(),
                    line_color=colors[i % len(colors)],
                    opacity=0.7,  # è®¾ç½®å¡«å……é€æ˜åº¦
                    line=dict(width=2)  # åŠ ç²—çº¿æ¡
            ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 1],
                    tickformat='.1%',
                    tickfont=dict(color='black', size=12),  # è®¾ç½®åˆ»åº¦æ ‡ç­¾ä¸ºé»‘è‰²ï¼Œè°ƒæ•´å­—ä½“å¤§å°
                    gridcolor='lightgray',  # è®¾ç½®ç½‘æ ¼çº¿é¢œè‰²
                    showline=True,  # æ˜¾ç¤ºè½´çº¿
                    linewidth=1,  # è½´çº¿å®½åº¦
                    linecolor='black'  # è½´çº¿é¢œè‰²
                ),
                angularaxis=dict(
                    tickfont=dict(color='black', size=12),  # è®¾ç½®è§’åº¦è½´æ ‡ç­¾ä¸ºé»‘è‰²ï¼Œè°ƒæ•´å­—ä½“å¤§å°
                    gridcolor='lightgray',  # è®¾ç½®ç½‘æ ¼çº¿é¢œè‰²
                    showline=True,  # æ˜¾ç¤ºè½´çº¿
                    linewidth=1,  # è½´çº¿å®½åº¦
                    linecolor='black'  # è½´çº¿é¢œè‰²
                ),
                bgcolor='white',  # è®¾ç½®èƒŒæ™¯è‰²ä¸ºç™½è‰²
                domain=dict(x=[0, 1], y=[0.15, 0.85])  # è°ƒæ•´é›·è¾¾å›¾çš„ä½ç½®ï¼Œå‘ä¸‹ç§»åŠ¨
            ),
            showlegend=True,
            title=dict(
                text="æ¨¡å‹è·¨åŸŸæ³›åŒ–èƒ½åŠ›é›·è¾¾å›¾",
                font=dict(size=16, color='black'),  # è®¾ç½®æ ‡é¢˜å­—ä½“å’Œé¢œè‰²
                y=0.95  # è°ƒæ•´æ ‡é¢˜ä½ç½®
            ),
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1,
                font=dict(size=12),  # è®¾ç½®å›¾ä¾‹å­—ä½“å¤§å°
                bgcolor='rgba(255, 255, 255, 0.8)'  # è®¾ç½®å›¾ä¾‹èƒŒæ™¯è‰²
            ),
            paper_bgcolor='white',  # è®¾ç½®å›¾è¡¨èƒŒæ™¯è‰²
            plot_bgcolor='white',  # è®¾ç½®ç»˜å›¾åŒºåŸŸèƒŒæ™¯è‰²
            margin=dict(t=120, b=50, l=50, r=50)  # å¢åŠ é¡¶éƒ¨è¾¹è·
        )
        
        return fig
    except Exception as e:
        st.warning(f"åˆ›å»ºé›·è¾¾å›¾æ—¶å‡ºé”™: {e}")
        return None

def show_cross_domain_analysis():
    """æ˜¾ç¤ºè·¨åŸŸæ³›åŒ–èƒ½åŠ›åˆ†æ"""
    st.subheader("ğŸ”„ è·¨åŸŸæ³›åŒ–èƒ½åŠ›åˆ†æ")
    
    # è·å–æ¨¡å‹å¯¹æ¯”æ•°æ®
    comparison_data = results_loader.get_model_comparison_data()
    
    if not comparison_data:
        st.warning("âŒ æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹å¯¹æ¯”æ•°æ®")
        return
    
    # åˆ›å»ºä¸¤åˆ—ç”¨äºé€‰æ‹©
    col1, col2 = st.columns(2)
    
    with col1:
        # æ¨¡å‹å¤šé€‰
        available_models = list(comparison_data.keys())
        selected_models = st.multiselect(
            "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹:",
            options=available_models,
            default=available_models,  # é»˜è®¤é€‰æ‹©æ‰€æœ‰æ¨¡å‹
            help="å¯ä»¥é€‰æ‹©å¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”"
        )
    
    with col2:
        # æ•°æ®é›†é€‰æ‹©
        dataset_options = {
            'test': 'In-Domain Test',
            'test_cross_device': 'Cross-Device',
            'test_cross_env': 'Cross-Environment',
            'test_cross_user': 'Cross-User'
        }
        selected_datasets = st.multiselect(
            "é€‰æ‹©è¦æ˜¾ç¤ºçš„æ•°æ®é›†:",
            options=list(dataset_options.keys()),
            default=list(dataset_options.keys()),  # é»˜è®¤é€‰æ‹©æ‰€æœ‰æ•°æ®é›†
            format_func=lambda x: dataset_options[x],
            help="å¯ä»¥é€‰æ‹©æ˜¾ç¤ºä¸åŒåŸŸçš„æ•°æ®é›†"
        )
    
    if not selected_models:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
        return
        
    if not selected_datasets:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ•°æ®é›†")
        return
    
    # åˆ›å»ºæ ‡ç­¾é¡µæ¥æ˜¾ç¤ºä¸åŒçš„å¯è§†åŒ–æ–¹å¼
    tab1, tab2, tab3, tab4 = st.tabs(["æŠ˜çº¿å›¾å¯¹æ¯”", "æ¡å½¢å›¾å¯¹æ¯”", "é›·è¾¾å›¾å¯¹æ¯”", "ğŸ“Š æ€§èƒ½è¯¦æƒ…"])
    
    with tab1:
        # æŠ˜çº¿å›¾å¯¹æ¯”
        fig_line = plot_cross_domain_comparison(
            comparison_data,
            selected_models,
            selected_datasets
        )
        if fig_line:
            st.plotly_chart(fig_line, use_container_width=True)
    
    with tab2:
        # è¿‡æ»¤é€‰ä¸­çš„æ¨¡å‹æ•°æ®
        filtered_data = {model: data for model, data in comparison_data.items() 
                        if model in selected_models}
        
        # æ¡å½¢å›¾å¯¹æ¯”
        fig_bar = plot_model_comparison_bar(filtered_data, "æ¨¡å‹è·¨åŸŸæ³›åŒ–èƒ½åŠ›å¯¹æ¯”")
        if fig_bar:
            st.plotly_chart(fig_bar, use_container_width=True)
    
    with tab3:
        # é›·è¾¾å›¾å¯¹æ¯”
        fig_radar = plot_cross_domain_radar(
            comparison_data,
            selected_models
        )
        if fig_radar:
            st.plotly_chart(fig_radar, use_container_width=True)
    
    with tab4:
        # æ€§èƒ½è¯¦æƒ…è¡¨æ ¼
        st.subheader("ğŸ“Š æ€§èƒ½è¯¦æƒ…")
        
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = []
        processed_models = set()  # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„æ¨¡å‹
        
        for model in selected_models:
            if model in comparison_data and model not in processed_models:  # ç¡®ä¿æ¯ä¸ªæ¨¡å‹åªå¤„ç†ä¸€æ¬¡
                # è·å–åŸå§‹æ•°å€¼
                test_acc = comparison_data[model].get('test_accuracy', 0)
                cross_device = comparison_data[model].get('cross_device', 0)
                cross_env = comparison_data[model].get('cross_env', 0)
                cross_user = comparison_data[model].get('cross_user', 0)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_performance = (test_acc + cross_device + cross_env + cross_user) / 4
                
                row = {
                    'Model': model.upper(),
                    'In-Domain Test': test_acc,
                    'Cross-Device': cross_device,
                    'Cross-Environment': cross_env,
                    'Cross-User': cross_user,
                    'Average': avg_performance
                }
                table_data.append(row)
                processed_models.add(model)  # æ ‡è®°æ¨¡å‹å·²å¤„ç†
        
        # è½¬æ¢ä¸ºDataFrameå¹¶æŒ‰å¹³å‡æ€§èƒ½æ’åº
        df = pd.DataFrame(table_data)
        df = df.sort_values('Average', ascending=False)
        
        # è®¾ç½®è¡¨æ ¼æ ·å¼
        def highlight_max(s):
            is_max = s == s.max()
            return ['background-color: rgba(144, 238, 144, 0.3)' if v else '' for v in is_max]
        
        def highlight_model(s):
            return ['font-weight: bold' if i == 0 else '' for i in range(len(s))]
        
        # è‡ªå®šä¹‰æ ·å¼
        styles = [
            # è¡¨å¤´æ ·å¼
            {'selector': 'th',
             'props': [
                 ('background-color', '#2c3e50'),
                 ('color', 'white'),
                 ('font-weight', 'bold'),
                 ('text-align', 'center'),
                 ('padding', '12px 8px'),
                 ('border', '1px solid #34495e'),
                 ('font-size', '14px'),
                 ('text-transform', 'uppercase'),
                 ('letter-spacing', '0.5px')
             ]},
            # å•å…ƒæ ¼æ ·å¼
            {'selector': 'td',
             'props': [
                 ('text-align', 'center'),
                 ('padding', '10px 8px'),
                 ('border', '1px solid #e0e0e0'),
                 ('font-size', '13px'),
                 ('color', '#2c3e50')
             ]},
            # è¡¨æ ¼å®¹å™¨æ ·å¼
            {'selector': '',
             'props': [
                 ('border-collapse', 'collapse'),
                 ('border', '1px solid #e0e0e0'),
                 ('box-shadow', '0 2px 4px rgba(0,0,0,0.1)'),
                 ('border-radius', '4px'),
                 ('overflow', 'hidden')
             ]},
            # äº¤æ›¿è¡Œæ ·å¼
            {'selector': 'tr:nth-of-type(even)',
             'props': [
                 ('background-color', '#f8f9fa')
             ]},
            # é¼ æ ‡æ‚¬åœæ ·å¼
            {'selector': 'tr:hover',
             'props': [
                 ('background-color', '#f5f5f5')
             ]},
            # Modelåˆ—æ ·å¼
            {'selector': 'td:first-child',
             'props': [
                 ('font-weight', 'bold'),
                 ('background-color', '#f8f9fa'),
                 ('border-right', '2px solid #e0e0e0')
             ]},
            # Averageåˆ—æ ·å¼
            {'selector': 'td:last-child',
             'props': [
                 ('font-weight', 'bold'),
                 ('background-color', '#f8f9fa'),
                 ('border-left', '2px solid #e0e0e0')
             ]}
        ]
        
        # æ˜¾ç¤ºè¡¨æ ¼
        st.dataframe(
            df.style
            .format({
                'In-Domain Test': '{:.2%}',
                'Cross-Device': '{:.2%}',
                'Cross-Environment': '{:.2%}',
                'Cross-User': '{:.2%}',
                'Average': '{:.2%}'
            })
            .apply(highlight_max, subset=['In-Domain Test', 'Cross-Device', 'Cross-Environment', 'Cross-User', 'Average'])
            .apply(highlight_model, subset=['Model'])
            .set_table_styles(styles)
            .set_properties(**{
                'text-align': 'center',
                'min-width': '100px'
            }),
            use_container_width=True,
            height=400
        )
        
        # æ·»åŠ è¡¨æ ¼è¯´æ˜
        st.markdown("""
        <div style='font-size: 13px; color: #666; margin-top: 15px; padding: 10px; background-color: #f8f9fa; border-radius: 4px; border-left: 4px solid #2c3e50;'>
        <p style='margin: 0 0 8px 0; font-weight: bold; color: #2c3e50;'>ğŸ“ è¡¨æ ¼è¯´æ˜ï¼š</p>
        <ul style='margin: 0; padding-left: 20px;'>
            <li>æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡å‡ä»¥ç™¾åˆ†æ¯”å½¢å¼æ˜¾ç¤º</li>
            <li>æµ…ç»¿è‰²èƒŒæ™¯è¡¨ç¤ºè¯¥åˆ—ä¸­çš„æœ€é«˜æ€§èƒ½</li>
            <li>Average åˆ—è¡¨ç¤ºæ¨¡å‹åœ¨æ‰€æœ‰åŸŸçš„å¹³å‡æ€§èƒ½</li>
            <li>è¡¨æ ¼æŒ‰å¹³å‡æ€§èƒ½é™åºæ’åˆ—</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
    
    # æœ€ä½³æ¨¡å‹ä¿¡æ¯
    st.subheader("ğŸ† æœ€ä½³æ¨¡å‹")
    best_models = results_loader.get_best_model_info()
    
    # æ˜¾ç¤ºæ¯ä¸ªåŸŸçš„æœ€ä½³æ¨¡å‹
    cols = st.columns(4)
    with cols[0]:
        st.metric(
            "In-Domain Testæœ€ä½³æ¨¡å‹",
            f"{best_models['test_accuracy']['model'].upper()}",
            f"{best_models['test_accuracy']['accuracy']:.1%}"
        )
    with cols[1]:
        st.metric(
            "Cross-Deviceæœ€ä½³æ¨¡å‹",
            f"{best_models['cross_device']['model'].upper()}",
            f"{best_models['cross_device']['accuracy']:.1%}"
        )
    with cols[2]:
        st.metric(
            "Cross-Environmentæœ€ä½³æ¨¡å‹",
            f"{best_models['cross_env']['model'].upper()}",
            f"{best_models['cross_env']['accuracy']:.1%}"
        )
    with cols[3]:
        st.metric(
            "Cross-Useræœ€ä½³æ¨¡å‹",
            f"{best_models['cross_user']['model'].upper()}",
            f"{best_models['cross_user']['accuracy']:.1%}"
        )

def game_mode():
    """æ¸¸æˆæ¨¡å¼ç•Œé¢"""
    
    # æ¸¸æˆçŠ¶æ€åˆå§‹åŒ–
    if 'game_started' not in st.session_state:
        st.session_state.game_started = False
    if 'user_wins' not in st.session_state:
        st.session_state.user_wins = 0
    if 'ai_wins' not in st.session_state:
        st.session_state.ai_wins = 0
    if 'target_wins' not in st.session_state:
        st.session_state.target_wins = 3
    if 'game_round' not in st.session_state:
        st.session_state.game_round = 0
    if 'game_over' not in st.session_state:
        st.session_state.game_over = False
    if 'total_score' not in st.session_state:
        st.session_state.total_score = 0
    
    # å¦‚æœæ¸¸æˆæœªå¼€å§‹ï¼Œæ˜¾ç¤ºæ¸¸æˆè®¾ç½®å’Œè§„åˆ™
    if not st.session_state.game_started:
        show_game_setup()
    elif st.session_state.game_over:
        show_game_over()
    else:
        show_game_interface()

def show_game_setup():
    """æ˜¾ç¤ºæ¸¸æˆè®¾ç½®å’Œè§„åˆ™"""
    # æ·»åŠ ä¸€äº›æ ·å¼ - æ•´ä½“å‘ä¸Šç§»åŠ¨
    st.markdown("""
    <style>
    .main > div {
        padding-top: 1rem !important;
    }
    .game-title {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        background: linear-gradient(45deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1.5rem;
        margin-top: 2rem;
        padding-top: 1rem;
    }
    .game-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 15px;
        color: white;
        margin-bottom: 1rem;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    }
    .score-badge {
        background: linear-gradient(45deg, #ff6b6b, #feca57);
        color: white;
        padding: 0.8rem;
        border-radius: 15px;
        display: block;
        margin: 0.3rem;
        font-weight: bold;
        text-align: center;
        width: 100%;
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        font-size: 0.9rem;
        line-height: 1.3;
    }
    
    /* èƒœåˆ©ç‰¹æ•ˆ */
    .victory-effect {
        animation: victoryPulse 2s ease-in-out infinite;
        background: linear-gradient(45deg, #ff6b6b, #feca57, #48dbfb, #ff9ff3);
        background-size: 400% 400%;
        animation: victoryGradient 3s ease infinite, victoryPulse 1.5s ease-in-out infinite;
    }
    
    @keyframes victoryGradient {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    @keyframes victoryPulse {
        0% { transform: scale(1); box-shadow: 0 0 20px rgba(255, 107, 107, 0.3); }
        50% { transform: scale(1.02); box-shadow: 0 0 40px rgba(255, 107, 107, 0.6); }
        100% { transform: scale(1); box-shadow: 0 0 20px rgba(255, 107, 107, 0.3); }
    }
    
    /* å¤±è´¥ç‰¹æ•ˆ */
    .defeat-effect {
        animation: defeatShake 0.5s ease-in-out 3;
        background: linear-gradient(45deg, #74b9ff, #0984e3, #a29bfe, #6c5ce7);
        background-size: 400% 400%;
        animation: defeatGradient 2s ease infinite, defeatShake 0.8s ease-in-out 2;
    }
    
    @keyframes defeatGradient {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    @keyframes defeatShake {
        0%, 100% { transform: translateX(0); }
        25% { transform: translateX(-5px); }
        75% { transform: translateX(5px); }
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown('<div class="game-title">ğŸ® WiFi CSI Activity Recognition Challenge</div>', unsafe_allow_html=True)
    
    # æ¸¸æˆä»‹ç»å¡ç‰‡
    with st.container():
        st.markdown("""
        <div class="game-card">
        <h3>ğŸ¯ Challenge Rules</h3>
        <p>ğŸ“Š è§‚å¯ŸWiFi CSIçƒ­åŠ›å›¾ï¼Œè¯†åˆ«äººä½“æ´»åŠ¨ç±»å‹</p>
        <p>ğŸ¤– ä¸AIåŒå°ç«æŠ€ï¼Œçœ‹è°çš„è¯†åˆ«èƒ½åŠ›æ›´å¼º</p>
        <p>ğŸ† å…ˆè¾¾åˆ°ç›®æ ‡èƒœåˆ©è½®æ•°çš„ä¸€æ–¹è·èƒœ</p>
        </div>
        """, unsafe_allow_html=True)
    
    # æ´»åŠ¨ç±»å‹ã€å¾—åˆ†è§„åˆ™å’Œæ¸¸æˆè®¾ç½® - å·¦ä¸­å³æ’å¸ƒ
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        st.markdown("### ğŸƒâ€â™€ï¸ æ´»åŠ¨ç±»å‹")
        activities_info = [
            ("ğŸ¦˜", "è·³è·ƒ", "é«˜åŠ¨æ€æ´»åŠ¨ï¼Œä¿¡å·å˜åŒ–å‰§çƒˆ"),
            ("ğŸƒ", "è·‘æ­¥", "æŒç»­è¿åŠ¨ï¼Œå‘¨æœŸæ€§ç‰¹å¾æ˜æ˜¾"),
            ("ğŸ§˜", "é™åå‘¼å¸", "å¾®åŠ¨æ£€æµ‹ï¼Œéœ€è¦é«˜ç²¾åº¦åˆ†æ"),
            ("ğŸš¶", "èµ°è·¯", "ä¸­ç­‰åŠ¨æ€ï¼Œæ­¥æ€ç‰¹å¾æ¸…æ™°"),
            ("ğŸ‘‹", "æŒ¥æ‰‹", "å±€éƒ¨è¿åŠ¨ï¼Œæ‰‹éƒ¨åŠ¨ä½œè¯†åˆ«")
        ]
        
        for emoji, name, desc in activities_info:
            st.markdown(f"**{emoji} {name}**: {desc}")
    
    with col2:
        st.markdown("### ğŸ† å¾—åˆ†è§„åˆ™")
        
        # 2x2å¸ƒå±€çš„å¾—åˆ†è§„åˆ™
        score_col1, score_col2 = st.columns(2)
        
        with score_col1:
            st.markdown("""
            <div class="score-badge">ä½ å¯¹AIé”™<br>+30åˆ†</div>
            """, unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True)
            st.markdown("""
            <div class="score-badge">åŒæ–¹éƒ½é”™<br>+10åˆ†</div>
            """, unsafe_allow_html=True)
        
        with score_col2:
            st.markdown("""
            <div class="score-badge">åŒæ–¹éƒ½å¯¹<br>+20åˆ†</div>
            """, unsafe_allow_html=True)
            st.markdown("<br>", unsafe_allow_html=True)
            st.markdown("""
            <div class="score-badge">ä½ é”™AIå¯¹<br>+5åˆ†</div>
            """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("### âš™ï¸ æ¸¸æˆè®¾ç½®")
        target_wins = st.selectbox(
            "èƒœåˆ©æ¡ä»¶ï¼š",
            [3, 5, 7, 10],
            index=0,
            help="å…ˆèƒœå‡ è½®è·èƒœ"
        )
        st.session_state.target_wins = target_wins
        
        # å¢åŠ ä¸€äº›ç©ºç™½é—´è·
        st.markdown("<br>", unsafe_allow_html=True)
        
        if st.button("ğŸš€ å¼€å§‹æŒ‘æˆ˜", type="primary", use_container_width=True):
            st.session_state.game_started = True
            st.session_state.user_wins = 0
            st.session_state.ai_wins = 0
            st.session_state.game_round = 1  # ä»ç¬¬1è½®å¼€å§‹
            st.session_state.game_over = False
            st.session_state.total_score = 0
            start_new_round()
            st.rerun()

def show_game_interface():
    """æ˜¾ç¤ºæ¸¸æˆè¿›è¡Œç•Œé¢"""
    # ç°ä»£åŒ–çš„çŠ¶æ€æ  - é¡µé¢å‘ä¸Šç§»åŠ¨
    st.markdown("""
    <style>
    .main > div {
        padding-top: 0.5rem !important;
    }
    .status-bar {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
        color: white;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin: 0.5rem;
    }
    .game-progress {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #007bff;
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # çŠ¶æ€æ 
    col1, col2, col3, col4, col5, col6 = st.columns([1, 1, 1, 1, 1, 1])
    
    with col1:
        st.metric("ğŸ† ä½ çš„èƒœåˆ©", st.session_state.user_wins, 
                 delta=f"ç›®æ ‡: {st.session_state.target_wins}")
    with col2:
        st.metric("ğŸ¤– AIèƒœåˆ©", st.session_state.ai_wins,
                 delta=f"ç›®æ ‡: {st.session_state.target_wins}")
    with col3:
        st.metric("ğŸ® å½“å‰è½®æ¬¡", st.session_state.game_round)
    with col4:
        st.metric("ğŸ’° æ€»åˆ†", st.session_state.total_score)
    with col5:
        # è®¡ç®—èƒœç‡
        total_decided = st.session_state.user_wins + st.session_state.ai_wins
        win_rate = (st.session_state.user_wins / max(1, total_decided)) * 100
        st.metric("ğŸ“Š èƒœç‡", f"{win_rate:.1f}%")
    with col6:
        if st.button("ğŸšª é€€å‡ºæ¸¸æˆ", help="è¿”å›æ¸¸æˆè®¾ç½®", type="secondary"):
            reset_game()
            st.rerun()
    
    # è¿›åº¦æ¡
    progress_text = f"ç¬¬ {st.session_state.game_round} è½® | ä½  {st.session_state.user_wins} : {st.session_state.ai_wins} AI"
    progress_percentage = max(st.session_state.user_wins, st.session_state.ai_wins) / st.session_state.target_wins
    st.progress(min(progress_percentage, 1.0), text=progress_text)
    
    # æ¸¸æˆä¸»ä½“
    if 'current_sample' not in st.session_state:
        # è‡ªåŠ¨å¼€å§‹æ–°è½®æ¬¡
        start_new_round()
        st.rerun()
    else:
        display_game_round()

def show_game_over():
    """æ˜¾ç¤ºæ¸¸æˆç»“æŸç•Œé¢"""
    # æ·»åŠ åº†ç¥åŠ¨ç”»æ ·å¼
    st.markdown("""
    <style>
    .winner-banner {
        background: linear-gradient(45deg, #ff6b6b, #feca57);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        margin-bottom: 2rem;
        font-size: 1.5rem;
        font-weight: bold;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    }
    .loser-banner {
        background: linear-gradient(45deg, #74b9ff, #0984e3);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        margin-bottom: 2rem;
        font-size: 1.5rem;
        font-weight: bold;
        box-shadow: 0 10px 30px rgba(0,0,0,0.3);
    }
    .final-stats {
        background: #f8f9fa;
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # åˆ¤æ–­èƒœè´Ÿå¹¶æ˜¾ç¤ºç»“æœ
    if st.session_state.user_wins >= st.session_state.target_wins:
        # æ»¡å±å¹•æ°”çƒç‰¹æ•ˆ
        for _ in range(3):  # è¿ç»­é‡Šæ”¾å¤šæ¬¡æ°”çƒ
            st.balloons()
        
        st.markdown("""
        <div class="winner-banner victory-effect">
        ğŸŠ æ­å–œè·èƒœï¼ä½ æˆ˜èƒœäº†AIï¼ ğŸ†<br>
        ä½ çš„WiFiæ„ŸçŸ¥èƒ½åŠ›è¶…è¶Šäº†äººå·¥æ™ºèƒ½ï¼
        </div>
        """, unsafe_allow_html=True)
        
        # æ·»åŠ é¢å¤–çš„åº†ç¥ç‰¹æ•ˆ
        st.success("ğŸŒŸ Amazing! You are a WiFi sensing expert! ğŸŒŸ")
        
        # å†æ¥ä¸€æ¬¡æ°”çƒæ•ˆæœ
        st.balloons()  # ç¬¬äºŒæ³¢æ°”çƒ
    else:
        st.markdown("""
        <div class="loser-banner defeat-effect">
        ğŸ¤– AIè·èƒœï¼ä½†ä½ è¡¨ç°å¾ˆæ£’ï¼ ğŸ’ª<br>
        ç»§ç»­ç»ƒä¹ ï¼Œä¸‹æ¬¡ä¸€å®šèƒ½æˆ˜èƒœAIï¼
        </div>
        """, unsafe_allow_html=True)
        # æ·»åŠ é¼“åŠ±ä¿¡æ¯
        st.info("ğŸ’ª Keep practicing! You're getting better! ğŸ’ª")
    
    # æœ€ç»ˆç»Ÿè®¡
    st.markdown("### ğŸ“Š æ¯”èµ›ç»Ÿè®¡")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ† ä½ çš„èƒœåˆ©", st.session_state.user_wins)
    with col2:
        st.metric("ğŸ¤– AIèƒœåˆ©", st.session_state.ai_wins)
    with col3:
        st.metric("ğŸ® æ€»è½®æ•°", st.session_state.game_round)
    with col4:
        st.metric("ğŸ’° æ€»å¾—åˆ†", st.session_state.total_score)
    
    # æˆå°±ç³»ç»Ÿ
    achievement = get_achievement_level(st.session_state.total_score)
    st.markdown(f"""
    ### ğŸ… æˆå°±ç­‰çº§
    **{achievement['emoji']} {achievement['level']}**  
    {achievement['description']}
    """)
    
    # å†æ¬¡æŒ‘æˆ˜æŒ‰é’®
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ”„ å†æ¬¡æŒ‘æˆ˜", type="primary", use_container_width=True):
            reset_game()
            st.rerun()

def start_new_round():
    """å¼€å§‹æ–°ä¸€è½®æ¸¸æˆ"""
    # å¢åŠ è½®æ¬¡è®¡æ•°ï¼ˆåœ¨å®é™…å¼€å§‹æ—¶ï¼‰
    if 'current_sample' not in st.session_state:
        # åªæœ‰åœ¨æ²¡æœ‰å½“å‰æ ·æœ¬æ—¶æ‰å¢åŠ è½®æ¬¡
        pass  # è½®æ¬¡åœ¨å¼€å§‹æ¸¸æˆæ—¶å·²ç»è®¾ç½®ä¸º1
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªCSIæ ·æœ¬
    csi_sample_dir = 'csi_samples'
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(csi_sample_dir):
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        csi_data = create_dummy_csi_data()
        selected_file = f"dummy_sample_round_{st.session_state.game_round}.npy"
    else:
        csi_files = [f for f in os.listdir(csi_sample_dir) if f.endswith('.npy')]
        if not csi_files:
            csi_data = create_dummy_csi_data()
            selected_file = f"dummy_sample_round_{st.session_state.game_round}.npy"
        else:
            selected_file = random.choice(csi_files)
            csi_data = csi_processor.load_csi_sample(os.path.join(csi_sample_dir, selected_file))
    
    if csi_data is None:
        st.error("âŒ æ— æ³•åŠ è½½CSIæ•°æ®")
        return
    
    # çœŸå®æ ‡ç­¾ï¼ˆä»æ–‡ä»¶åæ¨æ–­ï¼‰
    activity = extract_activity_from_filename(selected_file)
    
    # ä¿å­˜å½“å‰è½®æ¬¡çŠ¶æ€
    st.session_state.current_sample = {
        'data': csi_data,
        'name': selected_file,
        'activity': activity
    }
    
    # é‡ç½®è½®æ¬¡çŠ¶æ€
    st.session_state.user_answered = False
    if 'user_guess' in st.session_state:
        del st.session_state['user_guess']
    if 'ai_prediction' in st.session_state:
        del st.session_state['ai_prediction']

def display_game_round():
    """æ˜¾ç¤ºå½“å‰æ¸¸æˆè½®æ¬¡"""
    if 'current_sample' not in st.session_state:
        return
        
    try:
        current_sample = st.session_state.current_sample
        
        # æ¸¸æˆåŒºåŸŸæ ·å¼ - ç´§å‡‘å¸ƒå±€
        st.markdown("""
        <style>
        .game-area {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 1.5rem;
            border-radius: 15px;
            margin: 0.5rem 0;
        }
        .heatmap-container {
            background: white;
            padding: 1rem;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            margin-bottom: 0.5rem;
        }
        .answer-panel {
            background: white;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            border-left: 5px solid #007bff;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # æ˜¾ç¤ºCSIçƒ­åŠ›å›¾
        col1, col2 = st.columns([2.5, 1.5])
        
        with col1:
            st.markdown(f"""
            <div class="heatmap-container">
            <h4>ğŸ“Š WiFi CSI Heatmap - Round {st.session_state.game_round}</h4>
            </div>
            """, unsafe_allow_html=True)
            
            sample_data = current_sample['data']
            sample_name = current_sample['name']
            
            fig = plot_csi_heatmap(sample_data, f"WiFi CSI Signal Pattern Analysis")
            if fig:
                st.pyplot(fig, use_container_width=True)
                plt.close(fig)  # é‡Šæ”¾å†…å­˜
            else:
                st.error("æ— æ³•ç”ŸæˆCSIçƒ­åŠ›å›¾")
        
        with col2:
            st.markdown('<div class="answer-panel">', unsafe_allow_html=True)
            st.markdown("### ğŸ¤” è¯†åˆ«æŒ‘æˆ˜")
            
            # æ´»åŠ¨é€‰æ‹©
            activities = ["jumping", "running", "seated-breathing", "walking", "wavinghand"]
            activity_names = {
                "jumping": "ğŸ¦˜ è·³è·ƒ", 
                "running": "ğŸƒ è·‘æ­¥", 
                "seated-breathing": "ğŸ§˜ é™åå‘¼å¸",
                "walking": "ğŸš¶ èµ°è·¯", 
                "wavinghand": "ğŸ‘‹ æŒ¥æ‰‹"
            }
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ä½œç­”
            if not st.session_state.get('user_answered', False):
                # ç”¨æˆ·è¿˜æœªä½œç­”
                st.markdown("è§‚å¯Ÿä¸Šæ–¹çš„CSIçƒ­åŠ›å›¾ï¼Œé€‰æ‹©ä½ è®¤ä¸ºçš„æ´»åŠ¨ç±»å‹ï¼š")
                
                user_guess = st.selectbox(
                    "ä½ çš„é€‰æ‹©ï¼š",
                    activities,
                    format_func=lambda x: activity_names[x],
                    key=f"user_guess_{st.session_state.game_round}"
                )
                
                if st.button("âœ… æäº¤ç­”æ¡ˆ", type="primary", use_container_width=True):
                    # ç”¨æˆ·ä½œç­”
                    st.session_state.user_guess = user_guess
                    st.session_state.user_answered = True
                    
                    # ç”ŸæˆAIé¢„æµ‹
                    st.session_state.ai_prediction = get_ai_prediction(current_sample['data'])
                    st.rerun()
            
            else:
                # ç”¨æˆ·å·²ä½œç­”ï¼Œæ˜¾ç¤ºç»“æœå¯¹æ¯”
                show_round_results(activity_names)
            
            st.markdown('</div>', unsafe_allow_html=True)
                
    except Exception as e:
        st.error(f"æ˜¾ç¤ºæ¸¸æˆè½®æ¬¡æ—¶å‡ºé”™: {str(e)}")
        logger.error(f"Error in display_game_round: {str(e)}")

def get_ai_prediction(csi_data):
    """è·å–AIé¢„æµ‹ç»“æœ"""
    try:
        # å°è¯•ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œé¢„æµ‹
        model = model_loader.load_model('transformer')  # ä½¿ç”¨æœ€ä½³æ¨¡å‹
        if model:
            prediction, confidence = model_loader.predict(model, csi_data)
            ai_prediction = csi_processor.get_activity_name(prediction)
        else:
            # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨éšæœºé¢„æµ‹
            activities = ["jumping", "running", "seated-breathing", "walking", "wavinghand"]
            ai_prediction = random.choice(activities)
    except Exception as e:
        # å¦‚æœé¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨éšæœºé¢„æµ‹
        activities = ["jumping", "running", "seated-breathing", "walking", "wavinghand"]
        ai_prediction = random.choice(activities)
        logger.error(f"AI prediction failed: {str(e)}")
    
    return ai_prediction

def show_round_results(activity_names):
    """æ˜¾ç¤ºè½®æ¬¡ç»“æœ"""
    st.markdown("### ğŸ“‹ æœ¬è½®ç»“æœ")
    
    # è·å–ç­”æ¡ˆ
    current_sample = st.session_state.current_sample
    true_activity = current_sample['activity']
    user_guess = st.session_state.user_guess
    ai_prediction = st.session_state.ai_prediction
    
    # è®¡ç®—æ­£ç¡®æ€§
    user_correct = (user_guess == true_activity)
    ai_correct = (ai_prediction == true_activity)
    
    # æ˜¾ç¤ºç»“æœå¯¹æ¯”
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("**ğŸ¯ çœŸå®æ´»åŠ¨**")
        st.info(f"{activity_names[true_activity]}")
    
    with col2:
        st.markdown("**ğŸ‘¤ ä½ çš„ç­”æ¡ˆ**")
        if user_correct:
            st.success(f"âœ… {activity_names[user_guess]}")
        else:
            st.error(f"âŒ {activity_names[user_guess]}")
    
    with col3:
        st.markdown("**ğŸ¤– AIç­”æ¡ˆ**")
        if ai_correct:
            st.success(f"âœ… {activity_names[ai_prediction]}")
        else:
            st.error(f"âŒ {activity_names[ai_prediction]}")
    
    # è®¡ç®—å¹¶æ˜¾ç¤ºå¾—åˆ†
    round_score = calculate_round_score(user_correct, ai_correct)
    st.session_state.total_score += round_score
    
    # æ›´æ–°èƒœåˆ©è®¡æ•°å’Œæ˜¾ç¤ºç»“æœ
    if user_correct and not ai_correct:
        st.success(f"ğŸ‰ ä½ èµ¢äº†è¿™ä¸€è½®ï¼è·å¾— {round_score} åˆ†")
        st.session_state.user_wins += 1
    elif ai_correct and not user_correct:
        st.error(f"ğŸ˜ AIèµ¢äº†è¿™ä¸€è½®ï¼è·å¾— {round_score} åˆ†")
        st.session_state.ai_wins += 1
    elif user_correct and ai_correct:
        st.info(f"ğŸ¤ è¿™ä¸€è½®å¹³å±€ï¼è·å¾— {round_score} åˆ†")
    else:
        st.warning(f"ğŸ˜… ä½ ä»¬éƒ½ç­”é”™äº†ï¼è·å¾— {round_score} åˆ†")
    
    # æ£€æŸ¥æ¸¸æˆæ˜¯å¦ç»“æŸ
    if (st.session_state.user_wins >= st.session_state.target_wins or 
        st.session_state.ai_wins >= st.session_state.target_wins):
        st.session_state.game_over = True
        st.markdown("---")
        if st.button("ğŸŠ æŸ¥çœ‹æœ€ç»ˆç»“æœ", type="primary", use_container_width=True):
            st.rerun()
    else:
        # ç»§ç»­ä¸‹ä¸€è½®
        st.markdown("---")
        if st.button("â¡ï¸ ç»§ç»­ä¸‹ä¸€è½®", type="primary", use_container_width=True):
            # æ¸…ç†æœ¬è½®çŠ¶æ€å¹¶ç›´æ¥å¼€å§‹ä¸‹ä¸€è½®
            st.session_state.game_round += 1
            for key in ['current_sample', 'user_answered', 'user_guess', 'ai_prediction']:
                if key in st.session_state:
                    del st.session_state[key]
            # ç›´æ¥å¼€å§‹æ–°ä¸€è½®ï¼Œä¸éœ€è¦é¢å¤–ç‚¹å‡»
            start_new_round()
            st.rerun()

def calculate_round_score(user_correct, ai_correct):
    """è®¡ç®—è½®æ¬¡å¾—åˆ†"""
    if user_correct and not ai_correct:
        return 30  # ä½ å¯¹AIé”™
    elif user_correct and ai_correct:
        return 20  # åŒæ–¹éƒ½å¯¹
    elif not user_correct and not ai_correct:
        return 10  # åŒæ–¹éƒ½é”™
    else:
        return 5   # ä½ é”™AIå¯¹

def get_achievement_level(total_score):
    """æ ¹æ®æ€»åˆ†è·å–æˆå°±ç­‰çº§"""
    if total_score >= 500:
        return {
            'level': 'CSIå¤§å¸ˆ',
            'emoji': 'ğŸ†',
            'description': 'æ‚¨å·²æˆä¸ºCSIæ„ŸçŸ¥é¢†åŸŸçš„ä¸“å®¶ï¼',
        }
    elif total_score >= 300:
        return {
            'level': 'WiFiä¸“å®¶',
            'emoji': 'ğŸ¥‡',
            'description': 'å¯¹WiFiæ„ŸçŸ¥æœ‰å¾ˆæ·±çš„ç†è§£ï¼',
        }
    elif total_score >= 200:
        return {
            'level': 'ä¿¡å·çŒæ‰‹',
            'emoji': 'ğŸ¥ˆ',
            'description': 'èƒ½å¤Ÿè¯†åˆ«å¤§éƒ¨åˆ†æ´»åŠ¨æ¨¡å¼ï¼',
        }
    elif total_score >= 50:
        return {
            'level': 'æ•°æ®æ¢ç´¢è€…',
            'emoji': 'ğŸ¥‰',
            'description': 'å¼€å§‹ç†è§£CSIæ•°æ®çš„å¥¥ç§˜ï¼',
        }
    else:
        return {
            'level': 'æ–°æ‰‹',
            'emoji': 'ğŸ”°',
            'description': 'ç»§ç»­æ¢ç´¢WiFiçš„éšå½¢ä¸–ç•Œï¼',
        }

def extract_activity_from_filename(filename):
    """ä»æ–‡ä»¶åæå–æ´»åŠ¨æ ‡ç­¾"""
    # æ ¹æ®æ–‡ä»¶å‘½åè§„åˆ™è§£ææ´»åŠ¨ç±»å‹
    filename_lower = filename.lower()
    
    # æ£€æŸ¥å„ç§æ´»åŠ¨ç±»å‹
    if 'jumping' in filename_lower:
        return 'jumping'
    elif 'running' in filename_lower:
        return 'running'
    elif 'seated-breathing' in filename_lower:
        return 'seated-breathing'
    elif 'walking' in filename_lower:
        return 'walking'
    elif 'wavinghand' in filename_lower:
        return 'wavinghand'
    
    # å¦‚æœæ— æ³•ä»æ–‡ä»¶åæ¨æ–­ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ª
    return random.choice(csi_processor.activity_names)

def reset_game():
    """é‡ç½®æ¸¸æˆ"""
    # é‡ç½®æ¸¸æˆçŠ¶æ€
    st.session_state.game_started = False
    st.session_state.user_wins = 0
    st.session_state.ai_wins = 0
    st.session_state.game_round = 0
    st.session_state.game_over = False
    st.session_state.target_wins = 3
    st.session_state.total_score = 0
    
    # æ¸…ç†è½®æ¬¡çŠ¶æ€
    keys_to_delete = ['current_sample', 'user_answered', 'user_guess', 'ai_prediction']
    for key in keys_to_delete:
        if key in st.session_state:
            del st.session_state[key]

if __name__ == "__main__":
    main() 