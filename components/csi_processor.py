import numpy as np
import os
import h5py
import pandas as pd
import json
from pathlib import Path

class CSIProcessor:
    """ç”¨äºå¤„ç†CSIæ•°æ®çš„ç±»"""
    
    def __init__(self):
        self.activity_names = [
            "jumping",      # è·³è·ƒ
            "running",      # è·‘æ­¥ 
            "seated-breathing",  # é™åå‘¼å¸
            "walking",      # èµ°è·¯
            "wavinghand"    # æŒ¥æ‰‹
        ]
        
        self.activity_mapping = {
            0: "jumping",
            1: "running", 
            2: "seated-breathing",
            3: "walking",
            4: "wavinghand"
        }
        
        self.chinese_names = {
            "jumping": "è·³è·ƒ ğŸ¦˜",
            "running": "è·‘æ­¥ ğŸƒ",
            "seated-breathing": "é™åå‘¼å¸ ğŸ§˜",
            "walking": "èµ°è·¯ ğŸš¶",
            "wavinghand": "æŒ¥æ‰‹ ğŸ‘‹"
        }
    
    def load_csi_sample(self, file_path):
        """
        åŠ è½½CSIæ ·æœ¬æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            CSIæ•°æ®æ•°ç»„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            if not os.path.exists(file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½æ–¹æ³•
            if file_path.endswith('.npy'):
                data = np.load(file_path)
            elif file_path.endswith('.h5') or file_path.endswith('.hdf5'):
                data = self._load_h5_file(file_path)
            elif file_path.endswith('.csv'):
                data = pd.read_csv(file_path).values
            else:
                print(f"âš ï¸ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path}")
                return self._create_dummy_data()
            
            # éªŒè¯æ•°æ®å½¢çŠ¶
            if data is None or len(data.shape) < 2:
                print(f"âš ï¸ æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {file_path}")
                return self._create_dummy_data()
            
            # æ ‡å‡†åŒ–æ•°æ®å½¢çŠ¶
            data = self._normalize_data_shape(data)
            
            return data
            
        except Exception as e:
            print(f"âŒ åŠ è½½CSIæ•°æ®å¤±è´¥: {e}")
            return self._create_dummy_data()
    
    def _load_h5_file(self, file_path):
        """åŠ è½½HDF5æ–‡ä»¶"""
        try:
            with h5py.File(file_path, 'r') as f:
                # å°è¯•å¸¸è§çš„æ•°æ®é”®å
                possible_keys = ['csi', 'data', 'csi_data', 'X', 'features']
                for key in possible_keys:
                    if key in f:
                        return f[key][:]
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå–ç¬¬ä¸€ä¸ªæ•°æ®é›†
                keys = list(f.keys())
                if keys:
                    return f[keys[0]][:]
                    
            return None
            
        except Exception as e:
            print(f"âŒ åŠ è½½H5æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _normalize_data_shape(self, data):
        """æ ‡å‡†åŒ–æ•°æ®å½¢çŠ¶ä¸º (time_steps, features)"""
        try:
            if len(data.shape) == 1:
                # ä¸€ç»´æ•°æ®ï¼Œreshapeä¸ºäºŒç»´
                data = data.reshape(-1, 1)
            elif len(data.shape) == 3:
                # ä¸‰ç»´æ•°æ®ï¼Œå±•å¹³æœ€åä¸¤ä¸ªç»´åº¦
                data = data.reshape(data.shape[0], -1)
            
            # ç¡®ä¿æ—¶é—´æ­¥é•¿åˆç†
            if data.shape[0] < 100:
                # å¦‚æœæ—¶é—´æ­¥å¤ªå°‘ï¼Œè½¬ç½®æ•°æ®
                data = data.T
            
            return data
            
        except Exception as e:
            print(f"âŒ æ ‡å‡†åŒ–æ•°æ®å½¢çŠ¶å¤±è´¥: {e}")
            return self._create_dummy_data()
    
    def _create_dummy_data(self):
        """åˆ›å»ºè™šæ‹ŸCSIæ•°æ®ç”¨äºæ¼”ç¤º"""
        # åˆ›å»º500ä¸ªæ—¶é—´æ­¥ï¼Œ232ä¸ªç‰¹å¾çš„è™šæ‹Ÿæ•°æ®
        time_steps = 500
        features = 232
        
        # åˆ›å»ºä¸€äº›æœ‰æ¨¡å¼çš„æ•°æ®
        t = np.linspace(0, 4*np.pi, time_steps)
        data = np.zeros((time_steps, features))
        
        for i in range(features):
            # ä¸åŒé¢‘ç‡çš„æ­£å¼¦æ³¢æ¨¡æ‹Ÿä¸åŒå­è½½æ³¢
            frequency = 0.1 + (i / features) * 2
            amplitude = 0.5 + 0.5 * np.sin(i * 0.1)
            noise = np.random.normal(0, 0.1, time_steps)
            data[:, i] = amplitude * np.sin(frequency * t) + noise
        
        return data
    
    def get_activity_name(self, prediction_index):
        """
        æ ¹æ®é¢„æµ‹ç´¢å¼•è·å–æ´»åŠ¨åç§°
        
        Args:
            prediction_index: é¢„æµ‹çš„ç±»åˆ«ç´¢å¼•
            
        Returns:
            æ´»åŠ¨åç§°
        """
        if prediction_index in self.activity_mapping:
            return self.activity_mapping[prediction_index]
        else:
            return self.activity_names[0]  # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ªæ´»åŠ¨
    
    def get_chinese_name(self, activity_name):
        """
        è·å–æ´»åŠ¨çš„ä¸­æ–‡åç§°
        
        Args:
            activity_name: è‹±æ–‡æ´»åŠ¨åç§°
            
        Returns:
            ä¸­æ–‡æ´»åŠ¨åç§°
        """
        return self.chinese_names.get(activity_name, activity_name)
    
    def extract_features(self, csi_data):
        """
        ä»CSIæ•°æ®ä¸­æå–ç‰¹å¾
        
        Args:
            csi_data: CSIæ•°æ®
            
        Returns:
            ç‰¹å¾å­—å…¸
        """
        try:
            features = {}
            
            # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
            features['mean'] = np.mean(csi_data)
            features['std'] = np.std(csi_data)
            features['min'] = np.min(csi_data)
            features['max'] = np.max(csi_data)
            
            # æ—¶åŸŸç‰¹å¾
            features['variance'] = np.var(csi_data)
            features['rms'] = np.sqrt(np.mean(csi_data**2))
            
            # ç©ºé—´ç‰¹å¾ï¼ˆè·¨å­è½½æ³¢ï¼‰
            if len(csi_data.shape) >= 2:
                features['spatial_mean'] = np.mean(csi_data, axis=0)
                features['spatial_std'] = np.std(csi_data, axis=0)
                features['correlation'] = np.corrcoef(csi_data.T) if csi_data.shape[1] > 1 else np.array([[1]])
            
            # æ—¶é—´ç‰¹å¾ï¼ˆè·¨æ—¶é—´æ­¥ï¼‰
            if csi_data.shape[0] > 1:
                features['temporal_diff'] = np.diff(csi_data, axis=0)
                features['energy'] = np.sum(csi_data**2, axis=1)
            
            return features
            
        except Exception as e:
            print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
            return {}
    
    def preprocess_for_model(self, csi_data):
        """
        ä¸ºæ¨¡å‹é¢„å¤„ç†CSIæ•°æ®
        
        Args:
            csi_data: åŸå§‹CSIæ•°æ®
            
        Returns:
            é¢„å¤„ç†åçš„æ•°æ®
        """
        try:
            # ç¡®ä¿æ•°æ®å½¢çŠ¶æ­£ç¡®
            data = self._normalize_data_shape(csi_data)
            
            # Z-scoreæ ‡å‡†åŒ–
            mean = np.mean(data, axis=0)
            std = np.std(data, axis=0)
            std[std == 0] = 1  # é¿å…é™¤é›¶
            data = (data - mean) / std
            
            # è£å‰ªæˆ–å¡«å……åˆ°å›ºå®šé•¿åº¦
            target_length = 500
            if data.shape[0] > target_length:
                # è£å‰ª
                data = data[:target_length, :]
            elif data.shape[0] < target_length:
                # å¡«å……
                padding = np.zeros((target_length - data.shape[0], data.shape[1]))
                data = np.vstack([data, padding])
            
            return data
            
        except Exception as e:
            print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            return self._create_dummy_data()
    
    def get_sample_files(self, directory='csi_samples'):
        """
        è·å–æ ·æœ¬æ–‡ä»¶åˆ—è¡¨
        
        Args:
            directory: æ ·æœ¬æ–‡ä»¶ç›®å½•
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            if not os.path.exists(directory):
                print(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {directory}")
                return []
            
            # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
            extensions = ['.npy', '.h5', '.hdf5', '.csv']
            files = []
            
            for ext in extensions:
                pattern = f"*{ext}"
                files.extend(Path(directory).glob(pattern))
            
            return [str(f) for f in files]
            
        except Exception as e:
            print(f"âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def analyze_data_quality(self, csi_data):
        """
        åˆ†ææ•°æ®è´¨é‡
        
        Args:
            csi_data: CSIæ•°æ®
            
        Returns:
            è´¨é‡æŠ¥å‘Šå­—å…¸
        """
        try:
            report = {}
            
            # åŸºæœ¬ä¿¡æ¯
            report['shape'] = csi_data.shape
            report['size'] = csi_data.size
            report['dtype'] = str(csi_data.dtype)
            
            # ç¼ºå¤±å€¼æ£€æŸ¥
            report['has_nan'] = np.isnan(csi_data).any()
            report['has_inf'] = np.isinf(csi_data).any()
            report['nan_count'] = np.isnan(csi_data).sum()
            
            # æ•°æ®èŒƒå›´
            report['min_value'] = np.min(csi_data)
            report['max_value'] = np.max(csi_data)
            report['value_range'] = report['max_value'] - report['min_value']
            
            # ç»Ÿè®¡ä¿¡æ¯
            report['mean'] = np.mean(csi_data)
            report['std'] = np.std(csi_data)
            report['zero_ratio'] = np.sum(csi_data == 0) / csi_data.size
            
            # è´¨é‡è¯„åˆ† (0-1)
            quality_score = 1.0
            if report['has_nan'] or report['has_inf']:
                quality_score -= 0.3
            if report['zero_ratio'] > 0.8:
                quality_score -= 0.2
            if report['std'] < 0.001:
                quality_score -= 0.3
            
            report['quality_score'] = max(0, quality_score)
            
            return report
            
        except Exception as e:
            print(f"âŒ æ•°æ®è´¨é‡åˆ†æå¤±è´¥: {e}")
            return {'quality_score': 0, 'error': str(e)} 